{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clasificación de 20newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "66aAnzAV_hq6"
      },
      "outputs": [],
      "source": [
        "import os, re, csv, math, codecs, logging\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "import gdown\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# from keras.metrics import F1Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bq2K-KNtLacL"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, remove = ['headers', 'footers', 'quotes'])\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', shuffle=True, remove = ['headers', 'footers', 'quotes'])\n",
        "class_num = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8VHcRGiLARi",
        "outputId": "57cdd2f2-13b2-4a6b-d050-0af5a097cec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-26 18:14:26--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.121, 108.157.254.102, 108.157.254.124, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M   267MB/s    in 2.4s    \n",
            "\n",
            "2024-06-26 18:14:29 (267 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ],
      "source": [
        "# descargamos los embeddings de palabras de Fasttext para inglés y descomprimimos el archivo.\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc_N4ScILTdp",
        "outputId": "d332bda9-2f94-4895-d685-6e1b0d65ad80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading word embeddings...\n",
            "found 999995 word vectors\n"
          ]
        }
      ],
      "source": [
        "# cargamos los embeddings de palabras\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('wiki-news-300d-1M.vec', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print(f'found {len(embeddings_index)} word vectors')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WBzcDHYXMEEL"
      },
      "outputs": [],
      "source": [
        "# instanciamos el tokenizador\n",
        "token = Tokenizer(num_words=30000,\n",
        "                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                lower=True,\n",
        "                split=' ',\n",
        "                char_level=False,\n",
        "                oov_token=\"UNK\",\n",
        "                document_count=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hn_6uPC5MZEZ"
      },
      "outputs": [],
      "source": [
        "# fiteamos el tokenizador\n",
        "\n",
        "token.fit_on_texts(newsgroups_train.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2ygf-uVlL46e"
      },
      "outputs": [],
      "source": [
        "# obtenemos los diccionarios idx2word y word2idx\n",
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n",
        "# CHECK QUE EMPIEZA POR 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UFWmXJRGMeXK"
      },
      "outputs": [],
      "source": [
        "# cargamos en una matriz los embeddings de las palabras\n",
        "# presentes en el vocabulario\n",
        "embed_dim=300\n",
        "num_words=len(dictionary)+1\n",
        "embedding_matrix=np.zeros([num_words,embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if idx <= num_words and word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ajCS18eYBwA",
        "outputId": "20c53dea-c9d9-4ad4-dcf2-ac6d92d699af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105374, 300)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fGYvFbYwNjfB"
      },
      "outputs": [],
      "source": [
        "# se tokenizan los textos\n",
        "train_sequences=token.texts_to_sequences(newsgroups_train.data)\n",
        "test_sequences=token.texts_to_sequences(newsgroups_test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "OkV9rt_9NpKk"
      },
      "outputs": [],
      "source": [
        "# En este punto seleccionamos el tamaño de contexto a procesar en la variable `max_len`\n",
        "max_len=2000\n",
        "train_sequences=pad_sequences(train_sequences,maxlen=max_len)\n",
        "test_sequences=pad_sequences(test_sequences,maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QqLNwlPsUSJe"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional, LSTM, Dense, Embedding, Dropout, GRU\n",
        "from keras.models import Sequential\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD, Adam, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelos probados\n",
        "* Dos capas de LSTM con 100 y cuatro capas densas (128,64,32,20), con trainable = False y max_len = 500. Eso da un procentaje de 61.01% en val_accuracy. \n",
        "* Tres capas de LSTM con 100 y cuatro capas densas (128,64,32,20), con trainable = True y max_len = 500. Eso da un procentaje de 57.4% en val_accuracy. \n",
        "* Tres capas de LSTM con 100 con Bidirectional y tres capas densas (64,32,20), con trainable = False y max_len = 1200. Eso da un procentaje de 65.8% en val_accuracy. \n",
        "* Tres capas de GRU con 100 con Bidirectional y tres capas densas (64,32,20), con trainable = False y max_len = 1200. Eso da un procentaje de 64.7% en val_accuracy.\n",
        "* Tres capas de GRU con 120 con Bidirectional y tres capas densas (64,32,20), con trainable = False y max_len = 2000. Eso da un procentaje de 67.21% en val_accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AVcocHjTcRt",
        "outputId": "3166c35c-65b2-45b2-aebf-0c6aa69c3da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, None, 300)         31612200  \n",
            "                                                                 \n",
            " bidirectional_12 (Bidirect  (None, None, 240)         303840    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, None, 240)         0         \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirect  (None, None, 240)         260640    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, None, 240)         0         \n",
            "                                                                 \n",
            " bidirectional_14 (Bidirect  (None, 240)               260640    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 240)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 64)                15424     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 20)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32455484 (123.81 MB)\n",
            "Trainable params: 843284 (3.22 MB)\n",
            "Non-trainable params: 31612200 (120.59 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "# la primera capa es de embedding entrenable. Recordar que se puede variar el tamaño\n",
        "# del embedding a entrenar\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embed_dim, weights=[embedding_matrix], input_shape=(None,), trainable = False))\n",
        "\n",
        "model.add(((Bidirectional(GRU(120, return_sequences=True)))))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add((((Bidirectional(GRU(120, return_sequences=True))))))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add((((Bidirectional(GRU(120))))))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64, activation='swish'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='swish'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida es del tamaño del vocabulario\n",
        "model.add(Dense(class_num, activation='softmax'))\n",
        "\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "# notar que usamos la versión Sparse para utilizar sólo índices en lugar de OHE\n",
        "model.compile(loss=SparseCategoricalCrossentropy(), optimizer = Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkWOLsrOVAiz",
        "outputId": "22e147d1-615e-4039-a048-8535af4191d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "71/71 [==============================] - 55s 580ms/step - loss: 2.7878 - accuracy: 0.1056 - val_loss: 2.4707 - val_accuracy: 0.1542 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 39s 545ms/step - loss: 2.2059 - accuracy: 0.2294 - val_loss: 2.0410 - val_accuracy: 0.2665 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 39s 548ms/step - loss: 1.9014 - accuracy: 0.3176 - val_loss: 1.7599 - val_accuracy: 0.3677 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 40s 565ms/step - loss: 1.6668 - accuracy: 0.4037 - val_loss: 1.5354 - val_accuracy: 0.4419 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 40s 567ms/step - loss: 1.5073 - accuracy: 0.4556 - val_loss: 1.4043 - val_accuracy: 0.4932 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 40s 563ms/step - loss: 1.3745 - accuracy: 0.5164 - val_loss: 1.3578 - val_accuracy: 0.5144 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 38s 539ms/step - loss: 1.2915 - accuracy: 0.5552 - val_loss: 1.3056 - val_accuracy: 0.5471 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 40s 563ms/step - loss: 1.1917 - accuracy: 0.5928 - val_loss: 1.2411 - val_accuracy: 0.5877 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 40s 562ms/step - loss: 1.1307 - accuracy: 0.6241 - val_loss: 1.2178 - val_accuracy: 0.6005 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 40s 563ms/step - loss: 1.0607 - accuracy: 0.6477 - val_loss: 1.1761 - val_accuracy: 0.6160 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 38s 539ms/step - loss: 1.0032 - accuracy: 0.6604 - val_loss: 1.2023 - val_accuracy: 0.6098 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 40s 561ms/step - loss: 0.9556 - accuracy: 0.6767 - val_loss: 1.2021 - val_accuracy: 0.6032 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "71/71 [==============================] - 38s 539ms/step - loss: 0.9063 - accuracy: 0.6929 - val_loss: 1.1825 - val_accuracy: 0.6372 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "71/71 [==============================] - 40s 564ms/step - loss: 0.8661 - accuracy: 0.7085 - val_loss: 1.1833 - val_accuracy: 0.6368 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "71/71 [==============================] - 38s 538ms/step - loss: 0.8100 - accuracy: 0.7305 - val_loss: 1.1781 - val_accuracy: 0.6443 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "71/71 [==============================] - 38s 539ms/step - loss: 0.7788 - accuracy: 0.7410 - val_loss: 1.2224 - val_accuracy: 0.6465 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "71/71 [==============================] - 40s 563ms/step - loss: 0.7363 - accuracy: 0.7491 - val_loss: 1.2170 - val_accuracy: 0.6478 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "71/71 [==============================] - 38s 539ms/step - loss: 0.6750 - accuracy: 0.7745 - val_loss: 1.2203 - val_accuracy: 0.6549 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "71/71 [==============================] - 40s 563ms/step - loss: 0.6538 - accuracy: 0.7806 - val_loss: 1.2318 - val_accuracy: 0.6536 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "71/71 [==============================] - 38s 539ms/step - loss: 0.6103 - accuracy: 0.7964 - val_loss: 1.2791 - val_accuracy: 0.6567 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "71/71 [==============================] - 40s 565ms/step - loss: 0.5817 - accuracy: 0.8044 - val_loss: 1.2726 - val_accuracy: 0.6664 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "71/71 [==============================] - 40s 562ms/step - loss: 0.5396 - accuracy: 0.8201 - val_loss: 1.3465 - val_accuracy: 0.6664 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "71/71 [==============================] - 40s 570ms/step - loss: 0.5020 - accuracy: 0.8352 - val_loss: 1.3870 - val_accuracy: 0.6540 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "71/71 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.8407\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "71/71 [==============================] - 40s 562ms/step - loss: 0.4850 - accuracy: 0.8407 - val_loss: 1.4095 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "71/71 [==============================] - 38s 540ms/step - loss: 0.3910 - accuracy: 0.8758 - val_loss: 1.4231 - val_accuracy: 0.6721 - lr: 2.5000e-04\n",
            "Epoch 26/100\n",
            "71/71 [==============================] - 38s 536ms/step - loss: 0.3510 - accuracy: 0.8859 - val_loss: 1.4806 - val_accuracy: 0.6681 - lr: 2.5000e-04\n",
            "Epoch 27/100\n",
            "71/71 [==============================] - 38s 537ms/step - loss: 0.3245 - accuracy: 0.8970 - val_loss: 1.5411 - val_accuracy: 0.6650 - lr: 2.5000e-04\n",
            "Epoch 28/100\n",
            "71/71 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.9007\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "71/71 [==============================] - 40s 562ms/step - loss: 0.3134 - accuracy: 0.9007 - val_loss: 1.6079 - val_accuracy: 0.6642 - lr: 2.5000e-04\n",
            "Epoch 29/100\n",
            "71/71 [==============================] - 40s 568ms/step - loss: 0.2942 - accuracy: 0.9082 - val_loss: 1.5886 - val_accuracy: 0.6668 - lr: 6.2500e-05\n",
            "Epoch 30/100\n",
            "71/71 [==============================] - 40s 567ms/step - loss: 0.2897 - accuracy: 0.9111 - val_loss: 1.6083 - val_accuracy: 0.6655 - lr: 6.2500e-05\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\",\n",
        "    min_delta=0,\n",
        "    patience=5,\n",
        "    verbose=0,\n",
        "    mode=\"max\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0,\n",
        ")\n",
        "\n",
        "rlrop = ReduceLROnPlateau(\n",
        "    monitor = \"val_accuracy\",\n",
        "    factor = 0.25,\n",
        "    patience = 3,\n",
        "    verbose = 1,\n",
        "    min_lr = 0.5e-5\n",
        ")\n",
        "history = model.fit(train_sequences, newsgroups_train.target,\n",
        "                    batch_size=128,\n",
        "                    epochs=100,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping, rlrop]\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS3OkCaBaqzH",
        "outputId": "c27e764c-b791-4473-c6a8-5717f9982890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "236/236 [==============================] - 34s 135ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions = model.predict(test_sequences)\n",
        "predictions = predictions.argmax(axis=1)\n",
        "test_accuracy = np.sum(predictions == newsgroups_test.target) / len(newsgroups_test.target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpQ2BUnvS5Ra",
        "outputId": "af77c2ea-6e67-42bb-dc7a-0c3eadb266dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6123207647371216\n"
          ]
        }
      ],
      "source": [
        "print(test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdGO6SKwe5EW",
        "outputId": "4811a6bd-ab0d-4a26-f6b9-76df7f5c089e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6016668593920433\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "#F1\n",
        "predict_f1 = f1_score(newsgroups_test.target, predictions, average= \"macro\")\n",
        "print(predict_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No llegó a mejor que el primer TP, pero es el mejor porcentaje que llegué. En el primer TP, se logró aproximadamente un 67% en test. En este TP, se logró aproximadamente un 60% en test. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
